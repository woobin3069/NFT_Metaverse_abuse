{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_autoencoder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "b6vzRpHkjdZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Autoencoder 모델을 설계합니다.\n",
        "input_dim = X_train.shape[1] \n",
        "encoding_dim = 128\n",
        "\n",
        "input_layer = Input(shape=(input_dim, )) \n",
        "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(10e-5))(input_layer) \n",
        "encoder = Dense(encoding_dim,activation=\"relu\")(encoder) \n",
        "decoder = Dense(encoding_dim,activation='tanh')(encoder) \n",
        "encoder = Dense(int(encoding_dim / 2),activation=\"relu\")(encoder) \n",
        "decoder = Dense(int(encoding_dim / 2),activation='tanh')(encoder) \n",
        "encoder = Dense(int(encoding_dim / 4),activation=\"relu\")(encoder) \n",
        "decoder = Dense(int(encoding_dim / 4),activation='tanh')(encoder) \n",
        "encoder = Dense(int(encoding_dim / 8),activation=\"relu\")(encoder) \n",
        "decoder = Dense(int(encoding_dim / 8),activation='tanh')(encoder) \n",
        "decoder = Dense(input_dim, activation='relu')(decoder) \n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder) "
      ],
      "metadata": {
        "id": "WIdXBE0ejgZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 학습시킵니다.\n",
        "nb_epoch = 50 \n",
        "batch_size = 16 \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "with tf.device('/gpu:0'):\n",
        "  autoencoder.compile(optimizer=Adam(learning_rate=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), \n",
        "                      loss='mse', \n",
        "                      metrics= ['accuracy']) \n",
        "\n",
        "  history = autoencoder.fit(X_train, y_train, \n",
        "                            epochs=nb_epoch, \n",
        "                            batch_size=batch_size,\n",
        "                            validation_data=(X_test, y_test), \n",
        "                            verbose=1)"
      ],
      "metadata": {
        "id": "88tZEeDpjiVr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}